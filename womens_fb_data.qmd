---
title: "Neural Network Predictive Modeling"
format: 
  markdown:
    embed-resources: true
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
execute:
  echo: true
  output: true
editor: visual
---

```{r}
#| message: false
#| warning: false

options(conflicts.policy = "depends.ok")
library(tidyverse)
library(Matrix, exclude = c("expand", "pack", "unpack"))
library(lme4)
library(stringr)
library(broom)
library(skimr)
library(car, exclude = c("recode", "some"))
library(rmemore)
library(ggplot2)
library(lavaan)
library(lme4)
library(lubridate)

theme_set(theme_classic()) 

devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true")

path_data <- "data"
```

# read in full dataset
```{r}
df <- read_csv(here::here(path_data, "womens_orgs_WI_FB.csv"), show_col_types = FALSE)
names(df)
```

```{r}
# unique organizations
df_t <- df |>
  select(account.name, account.handle) |>
  mutate(account.name = as.factor(account.name),
         account.handle = as.factor(account.handle))

df_t |> count(account.handle)
df_t |> count(account.name)
```
> Given the inconsistent number of levels, we believe that "account.name" may be a more accurate "username" type metric.


# Variable selection
```{r}
df1 <- df |>
  select(date, type, 
         title, caption, description, message,
         statistics.actual.likeCount, statistics.actual.shareCount, statistics.actual.commentCount,
         account.name, account.handle, account.subscriberCount, account.pageDescription,
         account.pageCreatedDate, account.pageCategory, account.verified, 
         media)

df1 |> write_csv(here::here(path_data, "cleaned_womens_orgs_WI_FB.csv"))
```
> Process for selecting variables was decided while looking at the raw data, checking to see if responses were understandable/comprehensible, or could be cleaned. Uploaded for missingness EDA in Python.

# Checking variable levels
Type:
```{r}
df2 <- df1 |>
  mutate(type = factor(type),
         acc_category = account.pageCategory)
         
# check levels of 'type'
levels(df2$type)
df2 |> count(type)
```
> All reasonable types, 1407 NA which we will keep an eye on but is about 5% of dataset so can be imputed later.

Account verified:
```{r}
unique(df2$account.verified)
df2 |> count(account.verified)
```
> Date value and "and connections" are confusions here, caused by some kind of dataset issue. The date is, from rudimentary research on the platform, the date of verification, and the organization is under general verification. "and connections" is part of a sentence that got clipped across columns and does not particularly indicate verification or otherwise, so will be transformed to NA. With that, we end up with about 20% missing data. Could still reasonably impute.

```{r}
df2 <- df2 |>
  mutate(account.verified = if_else(account.verified == "and connections.", NA, account.verified))

df2 <- df2 |>
  mutate(account_verified_binary = if_else(account.verified == "FALSE", "no", "yes"))

# check to make sure it worked
df2 |> count(account_verified_binary)
```

Account category
```{r}
unique(df2$acc_category)
df2 |> count(acc_category)
```
> Useful variable that we want to keep, especially since multiple organizations (account.name) are associated with certain categories, but date variables cause some issues. Will bucket into a "None/other" category, and impute NAs during recipe building.

```{r}
# create an "other" bucket
df2 <- df2 |>
  mutate(acc_category = if_else(acc_category == "2009-09-29 16:07:26", "Other", acc_category),
         acc_category = if_else(acc_category == "2021-01-28 07:43:46", "Other", acc_category),
         acc_category = if_else(acc_category == "experience-based curriculum which", 
                                "Other", acc_category))
df2 <- df2 |>
  mutate(acc_category = factor(acc_category))

df2 |> count(acc_category)
```
Media
```{r}
# unique(df2$media)
```
> While a promising variable during eyeballing, cross-referencing between Python EDA and this file, the unique levels cannot be cleaned appropriately.

# Addressing missingness

## Removing empty observations
```{r}
# type cleaning
df3 <- df2 |>
  filter(!date == "NON_PROFIT") |>
  filter(!date == "and providing a powerful network.") |>
  filter(!date == "and leadership in this country in")

# df3 |> write_csv(here::here(path_data, "2cleaned_womens_orgs_WI_FB.csv"))
```
> Cross-referenced with missingness EDA, rows that do not have a valid datetime are empty. This drops 2110 observations. Continuous cross-reference with missingness EDA shows that this removes a good portion of the missingness we saw in the original EDA. (Completed in tandem during class.)

## New binary variables
```{r}
df4 <- df3 |>
  mutate(title_binary = if_else(is.na(title), "no text", "has title"),
         caption_binary = if_else(is.na(caption), "no text", "has caption"),
         description_binary = if_else(is.na(description), "no text", "has desc"))
```
> The next biggest concern was that many posts did not have titles, captions, or descriptions. These are optional formats in Facebook posts, which makes sense. After looking at many of the unique outputs, these strings could be useful with sentiment analysis added, but the strong amount of missingness means that imputation may not be meaningful. We have opted to create binaries for if posts do or do not have titles, captions, and descriptions; these are eye-grabbing parts of a post that may determine engagement. Future directions may include more nuanced sentiment analysis or NLP.

# Changing date variables
> Tidymodels is capable of handling datetime format data, so this will be applied as best practice for this variable format.

# Date split
```{r}
df5 <- df4 |>
  mutate(time_posted = str_extract(date, "(?<= ).*"),
         date_posted = str_extract(date, "^([^ ]+)")) |>
  mutate(time_posted = as.POSIXct(time_posted, format = "%H:%M:%S"),
         date_posted = as.Date(date_posted))
```


```{r}
df5 |>
  count(account.pageCreatedDate)

df5 <- df5 |>
  mutate(account.pageCreatedDate = as.POSIXct(account.pageCreatedDate, format = "%Y-%m-%d %H:%M:%S"))
```

> Due to the existence of some non-date variables, which are automatically transformed into NAs by the as.POSIXct (datetime format) we end up with 10271 NAs. This could plausibly be imputed, but again the amount of missingness is very high. This variable will not be used. Unlike title, caption, and description, the lack of a creation date is not meaningful to how many likes a post gets.

# Save cleaned file
```{r}
df5 |>
  write_csv(here::here(path_data, "sentiment_women_v4.csv"))
```







